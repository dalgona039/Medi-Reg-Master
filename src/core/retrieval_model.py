import numpy as np
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass

try:
    import google.generativeai as genai
    HAS_GENAI = True
except ImportError:
    genai = None
    HAS_GENAI = False


@dataclass
class RelevanceWeights:
    semantic_weight: float = 0.7
    structural_weight: float = 0.2
    contextual_weight: float = 0.1
    
    def __post_init__(self):
        total = self.semantic_weight + self.structural_weight + self.contextual_weight
        if abs(total - 1.0) > 1e-6:
            raise ValueError(
                f"Weights must sum to 1.0, got {total}. "
                f"(Î»â‚={self.semantic_weight}, Î»â‚‚={self.structural_weight}, Î»â‚ƒ={self.contextual_weight})"
            )
    
    def to_dict(self) -> Dict[str, float]:
        return {
            'semantic_weight': self.semantic_weight,
            'structural_weight': self.structural_weight,
            'contextual_weight': self.contextual_weight
        }


class HierarchicalRetrievalModel:
    def __init__(
        self,
        weights: Optional[RelevanceWeights] = None,
        max_depth: int = 5,
        depth_decay: float = 0.9
    ):
        self.weights = weights or RelevanceWeights()
        self.max_depth = max_depth
        self.depth_decay = depth_decay
        
        self.embedding_model = 'models/text-embedding-004'
    
    def relevance_score(
        self,
        node: Dict[str, Any],
        query: str,
        current_depth: int,
        parent_node: Optional[Dict[str, Any]] = None,
        query_embedding: Optional[np.ndarray] = None
    ) -> Tuple[float, Dict[str, float]]:
        semantic_score = self._semantic_relevance(node, query, query_embedding)
        structural_score = self._structural_relevance(current_depth)
        contextual_score = self._contextual_relevance(node, parent_node)
        
        total_score = (
            self.weights.semantic_weight * semantic_score +
            self.weights.structural_weight * structural_score +
            self.weights.contextual_weight * contextual_score
        )
        total_score = np.clip(total_score, 0.0, 1.0)
        
        component_scores = {
            'semantic': float(semantic_score),
            'structural': float(structural_score),
            'contextual': float(contextual_score),
            'total': float(total_score)
        }
        
        return float(total_score), component_scores
    
    def _semantic_relevance(
        self,
        node: Dict[str, Any],
        query: str,
        query_embedding: Optional[np.ndarray] = None
    ) -> float:
        node_title = node.get('title', '')
        node_summary = node.get('summary', '')
        node_text = f"{node_title}. {node_summary}".strip()
        
        if not node_text:
            return 0.0
        
        query_lower = query.lower()
        node_lower = node_text.lower()
        
        import re
        query_words = set(re.findall(r'\w+', query_lower))
        node_words = set(re.findall(r'\w+', node_lower))
        
        if not query_words:
            return 0.0
        
        overlap = len(query_words.intersection(node_words))
        similarity = overlap / len(query_words)
        
        title_lower = node_title.lower()
        for query_word in query_words:
            if query_word in title_lower:
                similarity = min(similarity + 0.2, 1.0)
                break
        
        return min(similarity, 1.0)
    
    def _semantic_relevance_with_embedding(
        self,
        node_text: str,
        query: str,
        query_embedding: Optional[np.ndarray] = None
    ) -> float:
        try:
            if query_embedding is None:
                query_result = genai.embed_content(
                    model=self.embedding_model,
                    content=query,
                    task_type="retrieval_query"
                )
                query_embedding = np.array(query_result['embedding'])
            
            node_result = genai.embed_content(
                model=self.embedding_model,
                content=node_text,
                task_type="retrieval_document"
            )
            node_embedding = np.array(node_result['embedding'])
            
            # Cosine similarity
            similarity = np.dot(query_embedding, node_embedding) / (
                np.linalg.norm(query_embedding) * np.linalg.norm(node_embedding)
            )
            
            # [-1, 1] â†’ [0, 1] ë³€í™˜
            normalized_similarity = (similarity + 1) / 2
            
            return float(np.clip(normalized_similarity, 0.0, 1.0))
            
        except Exception as e:
            print(f"âš ï¸ Embedding error: {e}, fallback to keyword matching")
            # Fallback to keyword matching
            return self._semantic_relevance(
                {'title': '', 'summary': node_text},
                query,
                None
            )
    
    def _structural_relevance(self, current_depth: int) -> float:
        """
        êµ¬ì¡°ì  relevance (ê¹Šì´ í˜ë„í‹°)
        
        Formula:
            structural(d) = depth_decay^d
            
        Rationale:
            - ë£¨íŠ¸ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
            - ê¹Šì´ dê°€ ì¦ê°€í•˜ë©´ exponential decay
            - depth_decay=0.9: d=0â†’1.0, d=1â†’0.9, d=2â†’0.81, ...
        
        Args:
            current_depth: í˜„ì¬ ë…¸ë“œì˜ ê¹Šì´ (root=0)
            
        Returns:
            0.0 ~ 1.0 ì‚¬ì´ì˜ ì ìˆ˜ (ê¹Šì„ìˆ˜ë¡ ë‚®ìŒ)
        """
        if current_depth >= self.max_depth:
            return 0.0
        
        # Exponential decay
        score = self.depth_decay ** current_depth
        
        return float(np.clip(score, 0.0, 1.0))
    
    def _contextual_relevance(
        self,
        node: Dict[str, Any],
        parent_node: Optional[Dict[str, Any]]
    ) -> float:
        """
        ë¬¸ë§¥ì  relevance (ë¶€ëª¨-ìì‹ ì¼ê´€ì„±)
        
        Formula:
            contextual(v,p) = coherence(v.text, p.text) if p exists else 1.0
        
        Rationale:
            - ë¶€ëª¨ ë…¸ë“œì™€ ì˜ë¯¸ì ìœ¼ë¡œ ì—°ê²°ë˜ì–´ ìˆìœ¼ë©´ ë†’ì€ ì ìˆ˜
            - ë¶€ëª¨ê°€ ì—†ìœ¼ë©´ (root) 1.0
            - Hierarchical êµ¬ì¡°ì˜ ì¼ê´€ì„± ê²€ì¦
        
        Args:
            node: í˜„ì¬ ë…¸ë“œ
            parent_node: ë¶€ëª¨ ë…¸ë“œ (rootì¸ ê²½ìš° None)
            
        Returns:
            0.0 ~ 1.0 ì‚¬ì´ì˜ coherence ì ìˆ˜
        """
        if parent_node is None:
            # Root nodeëŠ” í•­ìƒ coherent
            return 1.0
        
        # ë¶€ëª¨-ìì‹ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„
        node_title = node.get('title', '')
        parent_title = parent_node.get('title', '')
        
        if not node_title or not parent_title:
            return 0.5  # ì¤‘ë¦½
        
        # ê°„ë‹¨í•œ keyword overlap (ì‹¤ì œë¡œëŠ” embedding ì‚¬ìš©)
        node_words = set(node_title.lower().split())
        parent_words = set(parent_title.lower().split())
        
        if not parent_words:
            return 0.5
        
        overlap = len(node_words.intersection(parent_words))
        coherence = overlap / len(parent_words)
        
        # ì¼ì • ìˆ˜ì¤€ ì´ìƒì˜ coherenceëŠ” ë³´ì¥ (ì™„ì „íˆ ë‹¤ë¥¸ ë‹¨ì–´ì—¬ë„ ê³„ì¸µ êµ¬ì¡°ìƒ ì—°ê²°)
        coherence = max(coherence, 0.3)  # minimum coherence
        
        return min(coherence, 1.0)
    
    def rank_nodes(
        self,
        nodes: List[Dict[str, Any]],
        query: str,
        parent_node: Optional[Dict[str, Any]] = None,
        current_depth: int = 0
    ) -> List[Tuple[Dict[str, Any], float, Dict[str, float]]]:
        """
        ì—¬ëŸ¬ ë…¸ë“œë¥¼ relevance scoreë¡œ ì •ë ¬
        
        Args:
            nodes: í›„ë³´ ë…¸ë“œ ë¦¬ìŠ¤íŠ¸
            query: ì‚¬ìš©ì ì§ˆë¬¸
            parent_node: ë¶€ëª¨ ë…¸ë“œ
            current_depth: í˜„ì¬ ê¹Šì´
            
        Returns:
            [(node, score, components), ...] ì •ë ¬ëœ ë¦¬ìŠ¤íŠ¸ (ë†’ì€ ì ìˆ˜ ìš°ì„ )
        """
        scored_nodes = []
        
        for node in nodes:
            score, components = self.relevance_score(
                node=node,
                query=query,
                current_depth=current_depth,
                parent_node=parent_node
            )
            scored_nodes.append((node, score, components))
        
        # ì ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        scored_nodes.sort(key=lambda x: x[1], reverse=True)
        
        return scored_nodes
    
    def get_complexity_analysis(self) -> Dict[str, str]:
        """
        ì•Œê³ ë¦¬ì¦˜ ë³µì¡ë„ ë¶„ì„ (ì„ì‚¬ ë…¼ë¬¸ìš©)
        
        Returns:
            {
                'time_complexity': 'O(...)',
                'space_complexity': 'O(...)',
                'optimality': '...',
                'limitations': '...'
            }
        """
        return {
            'time_complexity': 'O(N) where N = number of visited nodes',
            'space_complexity': 'O(D) where D = max tree depth (DFS stack)',
            'optimality': 'Greedy best-first search (not optimal, but efficient)',
            'trade_off': 'Efficiency (90% context reduction) vs Completeness (may miss some relevant nodes)',
            'limitations': 'Early filtering error: if parent is incorrectly judged irrelevant, all descendants are pruned'
        }
    
    def explain_decision(
        self,
        node: Dict[str, Any],
        query: str,
        current_depth: int,
        parent_node: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        ë…¸ë“œ ì„ íƒ/ì œì™¸ ê²°ì •ì˜ ì„¤ëª… ìƒì„± (interpretability)
        
        Args:
            node: ë…¸ë“œ
            query: ì§ˆë¬¸
            current_depth: ê¹Šì´
            parent_node: ë¶€ëª¨ ë…¸ë“œ
            
        Returns:
            ì‚¬ëŒì´ ì½ì„ ìˆ˜ ìˆëŠ” ì„¤ëª… ë¬¸ìì—´
        """
        score, components = self.relevance_score(node, query, current_depth, parent_node)
        
        explanation = [
            f"\n{'='*60}",
            f"Node: {node.get('title', 'Untitled')}",
            f"Total Relevance Score: {score:.4f}",
            f"{'='*60}",
            "",
            "Component Breakdown:",
            f"  ğŸ” Semantic Relevance  (Î»â‚={self.weights.semantic_weight}): {components['semantic']:.4f}",
            f"     â†’ Query-node similarity based on content",
            "",
            f"  ğŸ—ï¸  Structural Relevance (Î»â‚‚={self.weights.structural_weight}): {components['structural']:.4f}",
            f"     â†’ Depth penalty (current depth: {current_depth}/{self.max_depth})",
            "",
            f"  ğŸ”— Contextual Relevance (Î»â‚ƒ={self.weights.contextual_weight}): {components['contextual']:.4f}",
            f"     â†’ Parent-child coherence",
            "",
            f"Final Score = {self.weights.semantic_weight}Ã—{components['semantic']:.4f} + "
            f"{self.weights.structural_weight}Ã—{components['structural']:.4f} + "
            f"{self.weights.contextual_weight}Ã—{components['contextual']:.4f} = {score:.4f}",
            f"{'='*60}\n"
        ]
        
        return "\n".join(explanation)


# Default model instance
default_model = HierarchicalRetrievalModel()
